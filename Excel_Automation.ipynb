{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0834f27f",
   "metadata": {
    "id": "0834f27f"
   },
   "source": [
    "# **Excel Automation for NYC Parking Data (2014-2017)**\n",
    "\n",
    "**Author:** Zahra Haider\n",
    "\n",
    "---\n",
    "\n",
    "# **üìå Introduction**\n",
    "\n",
    "After cleaning 41.6 million rows of NYC parking violations data, the next challenge emerged: how to share insights with stakeholders who prefer Excel. The raw dataset was too large for standard tools, requiring a memory-efficient automation approach.\n",
    "\n",
    "üîπ **Start:** Cleaned data existed in CSV format, but Excel was needed for broader accessibility.\n",
    "\n",
    "üîπ **Conflict:** Excel crashes with large datasets, and manual export was impractical.\n",
    "\n",
    "üîπ **Solution:** A Python pipeline using openpyxl and chunk processing to create a polished, analysis-ready Excel report.\n",
    "\n",
    "---\n",
    "\n",
    "## **‚öôÔ∏è Step 1: Access Data in Google Colab**\n",
    "\n",
    "### **A. Mount Google Drive**\n",
    "\n",
    "***Why?*** Colab provides cloud compute power to handle large files.\n",
    "\n",
    "***Verification:*** Confirmed file paths with ``!ls.``\n",
    "\n",
    "---\n",
    "\n",
    "### **B. File Paths**\n",
    "\n",
    "***Input:*** ``combined_2014-2017.csv`` (41.6M rows).\n",
    "\n",
    "***Output:*** ``parking_report.xlsx`` (subset for Excel compatibility).\n",
    "\n",
    "***Key Insight:*** Cloud environments bypass local memory limits.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "MNWXRh0xsJGh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23243,
     "status": "ok",
     "timestamp": 1744154370199,
     "user": {
      "displayName": "Zahra Haider",
      "userId": "06025542689674594607"
     },
     "user_tz": -60
    },
    "id": "MNWXRh0xsJGh",
    "outputId": "1404eb23-9183-4ff1-aa86-e2f716bed223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "combined_2014-2017.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Verify file path\n",
    "!ls \"/content/drive/MyDrive/nyc_parking_cleaned\"  # Replace with your actual folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8_NhtcWltD8z",
   "metadata": {
    "id": "8_NhtcWltD8z"
   },
   "source": [
    "## **üìÇ Step 2: Memory-Efficient Excel Automation**\n",
    "\n",
    "### **A. Initialize Workbook**\n",
    "\n",
    "- ***Lightweight Setup:*** Avoided loading full dataset into memory.\n",
    "\n",
    "### **B. Write Headers**\n",
    "\n",
    "- ***Efficiency:*** Read only column names initially.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "FopWNpNttKCX",
   "metadata": {
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1744154567857,
     "user": {
      "displayName": "Zahra Haider",
      "userId": "06025542689674594607"
     },
     "user_tz": -60
    },
    "id": "FopWNpNttKCX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "import os\n",
    "\n",
    "# Paths (update these)\n",
    "input_path = \"/content/drive/MyDrive/nyc_parking_cleaned/combined_2014-2017.csv\"\n",
    "output_path = \"/content/drive/MyDrive/nyc_parking_cleaned/parking_report.xlsx\"\n",
    "\n",
    "# Create a lightweight Excel workbook\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"Parking Summary\"\n",
    "\n",
    "# Write headers only first\n",
    "headers = pd.read_csv(input_path, nrows=0).columns.tolist()\n",
    "ws.append(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Uy1aZSVItwgN",
   "metadata": {
    "id": "Uy1aZSVItwgN"
   },
   "source": [
    "## **üîÑ Step 3: Process Data in Chunks**\n",
    "\n",
    "### **A. Chunked Reading**\n",
    "\n",
    "- ***Why 50K rows?*** Balanced speed and memory usage.\n",
    "\n",
    "### **B. Row Limit**\n",
    "\n",
    "- ***Tradeoff:*** Subset to 100K rows for Excel stability.\n",
    "\n",
    "### **C. Append Rows**\n",
    "\n",
    "- ***Streaming:*** Processed rows incrementally.\n",
    "\n",
    "***Result:*** 100K-row Excel report generated without crashes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "KzEW-sJqt2k8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22417,
     "status": "ok",
     "timestamp": 1744154653075,
     "user": {
      "displayName": "Zahra Haider",
      "userId": "06025542689674594607"
     },
     "user_tz": -60
    },
    "id": "KzEW-sJqt2k8",
    "outputId": "377cf030-693e-4534-b527-03cde8a89694"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-57eb33d05eda>:5: DtypeWarning: Columns (6,7,12,13,14,18,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(input_path, chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50,000 rows...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-57eb33d05eda>:5: DtypeWarning: Columns (3,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(input_path, chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100,000 rows...\r\n",
      "‚úÖ Final report contains 100,000 rows\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 50000  # Rows per batch\n",
    "total_rows = 0\n",
    "max_report_rows = 100000  # Limit Excel output size\n",
    "\n",
    "for chunk in pd.read_csv(input_path, chunksize=chunk_size):\n",
    "    if total_rows >= max_report_rows:\n",
    "        break\n",
    "\n",
    "    for _, row in chunk.iterrows():\n",
    "        ws.append(row.tolist())\n",
    "        total_rows += 1\n",
    "\n",
    "    print(f\"Processed {total_rows:,} rows...\", end='\\r')\n",
    "\n",
    "print(f\"\\n‚úÖ Final report contains {total_rows:,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RE0hX6mGuKfo",
   "metadata": {
    "id": "RE0hX6mGuKfo"
   },
   "source": [
    "## **üé® Step 4: Formatting for Readability**\n",
    "\n",
    "### **A. Header Styling**\n",
    "\n",
    "- ***Professional Touch:*** Improved visual hierarchy.\n",
    "\n",
    "### **B. Auto-Adjust Columns**\n",
    "\n",
    "- ***Dynamic Widths:*** Ensured readability without manual tweaks.\n",
    "\n",
    "### **C. Freeze Headers**\n",
    "\n",
    "- ***Usability:*** Kept headers visible during scrolling.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "jDkaeHCuuNWM",
   "metadata": {
    "executionInfo": {
     "elapsed": 5958,
     "status": "ok",
     "timestamp": 1744154727395,
     "user": {
      "displayName": "Zahra Haider",
      "userId": "06025542689674594607"
     },
     "user_tz": -60
    },
    "id": "jDkaeHCuuNWM"
   },
   "outputs": [],
   "source": [
    "from openpyxl.styles import Font, PatternFill\n",
    "\n",
    "# Format headers\n",
    "header_fill = PatternFill(start_color=\"4472C4\", fill_type=\"solid\")\n",
    "header_font = Font(bold=True, color=\"FFFFFF\")\n",
    "\n",
    "for cell in ws[1]:\n",
    "    cell.fill = header_fill\n",
    "    cell.font = header_font\n",
    "\n",
    "# Auto-adjust column widths\n",
    "for col in ws.columns:\n",
    "    max_len = max(len(str(cell.value)) for cell in col)\n",
    "    adjusted_width = min(max_len + 2, 30)  # Cap at 30 characters\n",
    "    ws.column_dimensions[col[0].column_letter].width = adjusted_width\n",
    "\n",
    "# Freeze header row\n",
    "ws.freeze_panes = \"A2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EH5pMb__uS5J",
   "metadata": {
    "id": "EH5pMb__uS5J"
   },
   "source": [
    "## **üíæ Step 5: Save & Download**\n",
    "\n",
    "### ***A. Save to Drive***\n",
    "\n",
    "- ***Persistence:*** Stored in Google Drive for collaboration.\n",
    "\n",
    "### **B. Direct Download**\n",
    "\n",
    "- ***Convenience:*** One-click access to the final report.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13pF57hCuYst",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 32378,
     "status": "ok",
     "timestamp": 1744154806530,
     "user": {
      "displayName": "Zahra Haider",
      "userId": "06025542689674594607"
     },
     "user_tz": -60
    },
    "id": "13pF57hCuYst",
    "outputId": "5a06a79a-1424-4c1e-ed66-de6c67d8d529"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report saved to Google Drive: /content/drive/MyDrive/nyc_parking_cleaned/parking_report.xlsx\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_fac8f171-649b-4fab-bd04-fc1b78aa7510\", \"parking_report.xlsx\", 12752127)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wb.save(output_path)\n",
    "print(f\"Report saved to Google Drive: {output_path}\")\n",
    "\n",
    "# Download directly to your computer\n",
    "from google.colab import files\n",
    "files.download(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac290750",
   "metadata": {
    "id": "ac290750"
   },
   "source": [
    "## **üîç Next Steps: Analysis Opportunities**\n",
    "\n",
    "With the Excel report, stakeholders can now:\n",
    "\n",
    "**1. Pivot Table Analysis**\n",
    "\n",
    "- ***Question:*** Which vehicle makes receive the most tickets?\n",
    "\n",
    "- ***Method:*** Pivot on vehicle_make and violation_code.\n",
    "\n",
    "**2. Time Trends**\n",
    "\n",
    "- ***Question:*** Are tickets increasing year-over-year?\n",
    "\n",
    "- ***Method:*** Group by issue_year and count violations.\n",
    "\n",
    "**3. Geospatial Mapping**\n",
    "\n",
    "- ***Question:*** Where are violation hotspots?\n",
    "\n",
    "- ***Method:*** Filter by violation_precinct and map in Excel 3D Maps.\n",
    "\n",
    "**4. Officer Activity**\n",
    "\n",
    "- ***Question:*** Who are the top 10 issuers?\n",
    "\n",
    "- ***Method:*** Rank issuer_code by ticket count.\n",
    "\n",
    "---\n",
    "\n",
    "## **üéØ Conclusion**\n",
    "\n",
    "This project bridged the gap between big data and user-friendly reporting by:\n",
    "\n",
    "- **Automating** Excel exports for large datasets.\n",
    "\n",
    "- **Optimizing** for memory and performance.\n",
    "\n",
    "- **Enabling** non-technical stakeholders to explore insights.\n",
    "\n",
    "**Key Takeaway:** Automation democratizes data access.\n",
    "\n",
    "**Tools Used**: Python, openpyxl, Pandas, Google Colab.\n",
    "\n",
    "**Author:** Zahra Haider\n",
    "\n",
    "---\n",
    "\n",
    "***üöÄ Now anyone can analyze NYC parking trends‚Äîno coding needed!***\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f06172",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
